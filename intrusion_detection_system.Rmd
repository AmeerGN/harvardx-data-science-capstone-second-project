---
title: "Intrusion Detection Systems (IDSs) using NSL-KDD Dataset"
author: "Ameer Nasrallah"
date: "01 March 2022"
output:
  bookdown::pdf_document2:
    number_sections: true
    toc: true
    extra_dependencies: ["float"]
bibliography: references.bib
csl: ieee.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\newpage

# Introduction

An intrusion detection system (IDS) is a system that automatically checks and analyzes network flow to detect and prevent abnormal activities [@chen2018effective]. This includes monitoring both user and system behaviors, such as the unauthorized access to network resources, and the analysis of network packet fields (e.g. IP address, flag, ports) [@selvakumar2018firefly]. Upon detecting an intrusion, the IDS alarms it to the management [@hajisalem2018hybrid].

An IDS can be classified based on the detection mechanism to knowledge-based [@chen2018effective] and behavior-based [@selvakumar2018firefly]. In knowledge-based (or signature-based) detection, the IDS uses misuse detection to detect known attacks by comparing between received packets and a predefined set of collected data (e.g. signature files). While in behavior-based (or anomaly-based) detection, the IDS uses anomaly detection to detect unknown attacks by comparing the system state with the normal activity profile it builds. Anomaly-based detection suffers from high false alarm rates. Despite that, it is still considered better than knowledge-based detection as it can detect novel or zero-day attacks. Hence, anomaly-based detection got more attention during the past twenty years, and there have been many research efforts to apply machine learning techniques in intrusion detection.

The goal of this project is to build two anomaly-based IDSs. The first system is a binary classification system that will classify a TCP connection (defined by certain attributes such as the port, protocol, etc) as either a normal activity or as an attack. While the second system will be a multi-class classification system that will classify the TCP connection as a normal activity or as one of four known attacks (DoS, Probing, R2L or U2R). Both systems will be built using NSL-KDD dataset [@tavallaee2009detailed] which provides the predictions of about 150000 simulated TCP connections.

We will evaluate the performance of each system using six classifiers (Recursive Partitioning, Naive Bayes, KNN, SVM, Random Forest, and MLP), given that the data is already divided into training and testing sets (about 15% of the data). For each classifier, we will apply 10-fold cross validation on the training set only to find the best tuned parameters. Then, the performance of each tuned classifier will be measured by predicting the testing set output. We will report different metrics, but we will focus mainly on three of them: overall accuracy (max), detection rates (max), and false alarm rates (min).

The rest of this report is organized as follows. We will start by studying the characteristics of NSL-KDD dataset. Then, we will explain the the methodology. Then, we will analyze the training set and tune the classifiers. Then, we will use the final tuned classifiers to predict the testing set. And finally, we will conclude all the work with future improvements.

# NSL-KDD Dataset Characteristics

```{r Read NSL-KDD training and testing sets, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(caret)
library(recipes)
library(doParallel)
library(knitr)

##########################################################
# Create train set, test set (final hold-out test set)
##########################################################

# Define NSL-KDD column names
basic_features <- c("duration",
                    "protocol_type",
                    "service",
                    "flag",
                    "src_bytes",
                    "dst_bytes",
                    "land",
                    "wrong_fragment",
                    "urgent")

content_features <- c("hot",
                      "num_failed_logins",
                      "logged_in",
                      "num_compromised",
                      "root_shell",
                      "su_attempted",
                      "num_root",
                      "num_file_creations",
                      "num_shells",
                      "num_access_files",
                      "num_outbound_cmds",
                      "is_host_login",
                      "is_guest_login")

time_based_traffic_features <- c("count",
                                 "srv_count",
                                 "serror_rate",
                                 "srv_serror_rate",
                                 "rerror_rate",
                                 "srv_rerror_rate",
                                 "same_srv_rate",
                                 "diff_srv_rate",
                                 "srv_diff_host_rate")

host_based_traffic_features <- c("dst_host_count",
                                 "dst_host_srv_count",
                                 "dst_host_same_srv_rate",
                                 "dst_host_diff_srv_rate",
                                 "dst_host_same_src_port_rate",
                                 "dst_host_srv_diff_host_rate",
                                 "dst_host_serror_rate",
                                 "dst_host_srv_serror_rate",
                                 "dst_host_rerror_rate",
                                 "dst_host_srv_rerror_rate")

# These are the final column names as specified in the original CSV files
col_names <- c(basic_features, content_features, time_based_traffic_features, host_based_traffic_features, "label", "difficulty")

if (file.exists("data/NSL-KDD.RData")) {
  load("data/NSL-KDD.RData")
} else {
  nsl_kdd_train_csv = read.csv(unz("data/NSL-KDD.zip", "KDDTrain+.txt"), col.names = col_names, header = FALSE)
  nsl_kdd_test_csv = read.csv(unz("data/NSL-KDD.zip", "KDDTest+.txt"), col.names = col_names, header = FALSE)
  # Remove difficulty column
  nsl_kdd_train_csv <- nsl_kdd_train_csv %>% select(-difficulty)
  nsl_kdd_test_csv <- nsl_kdd_test_csv %>% select(-difficulty)
  save(nsl_kdd_train_csv, nsl_kdd_test_csv, file = "data/NSL-KDD.RData")
}

prepare_data <- function(binary_classification, nsl_kdd_train_csv, nsl_kdd_test_csv) {
  if (binary_classification) {
    train_data <- nsl_kdd_train_csv %>%
                    mutate(label = ifelse(label == "normal", "X2", "X1"))
    train_data$label <- factor(train_data$label)
    test_data <- nsl_kdd_test_csv %>%
                  mutate(label = ifelse(label == "normal", "X2", "X1"))
    test_data$label <- factor(test_data$label)
  } else {
    dos_attacks = c("neptune", "back", "land", "pod", "smurf", "teardrop", "mailbomb", "apache2", "processtable", "udpstorm", "worm")
    probing_attacks = c("ipsweep", "nmap", "portsweep", "satan", "mscan", "saint")
    r2l_attacks = c("ftp_write", "guess_passwd", "imap", "multihop", "phf", "spy", "warezclient", "warezmaster", "sendmail", "named", "snmpgetattack", "snmpguess", "xlock", "xsnoop", "httptunnel")
    u2r_attacks = c("buffer_overflow", "loadmodule", "perl", "rootkit", "ps", "sqlattack", "xterm")
    
    label_to_multi_category <- function(label) {
      if (label == "normal") {
        return("X5")
      } else if (label %in% dos_attacks) {
        return("X4")
      } else if (label %in% probing_attacks) {
        return("X3")
      } else if (label %in% r2l_attacks) {
        return("X2")
      } else if (label %in% u2r_attacks) {
        return("X1")
      }
    }
    train_data <- nsl_kdd_train_csv %>%
                    mutate(label = sapply(label, label_to_multi_category))
    train_data$label <- factor(train_data$label)
    test_data <- nsl_kdd_test_csv %>%
                  mutate(label = sapply(label, label_to_multi_category))
    test_data$label <- factor(test_data$label)
    
    rm(dos_attacks, probing_attacks, r2l_attacks, u2r_attacks, label_to_multi_category)
  }
  return(list("train" = train_data, "test" = test_data))
}
binary_class_data <- prepare_data(TRUE, nsl_kdd_train_csv, nsl_kdd_test_csv)
multi_class_data <- prepare_data(FALSE, nsl_kdd_train_csv, nsl_kdd_test_csv)
```

NSL-KDD dataset [@tavallaee2009detailed] is one of the most effective datasets in the domain of intrusion detection. It is a modified version of KDDCUP'99 dataset [@kddCup], which was created in 1999. KDDCUP'99 is constructed from simulated TCP connections in a military network environment [@bamakan2016effective]. KDDCUP'99 had been the most widely used dataset to evaluate IDSs until recent years [@salo2018data]. However, researchers found some deficiencies that make it less reliable [@tavallaee2009detailed]:

1. Redundant records: this mainly affects the performance of any classifier such that it is biased towards more frequent records.
2. Low difficulty level: applying simple machine learning methods will give at least 86% accuracy, which makes it difficult to compare the different models as they will fall in the range of 86% to 100%.

To deal with these deficiencies, the following improvements were applied to NSLKDD [@tavallaee2009detailed]:

1. Removing all redundant records from train and test sets so that there will be no biasing.
2. Better sampling and distribution for the records which will increase the classification challenge.
3. Reasonable number of records in train and test sets. This makes it affordable to run experiments on the whole dataset without any need for sampling.

NSL-KDD still does not perfectly represent real networks. Nonetheless, it is still a reliable benchmark dataset to compare intrusion detection methods.

## Attacks Categories
NSL-KDD records are labeled as normal or attack. There are 39 different attacks distributed (with some overlap) as 22 attacks in the training set and 37 attacks in the testing set. These attacks fall into four basic categories detailed as follows:

* Denial of Service Attack (DoS): involves attacks which try to keep the machine's memory or computing resources too busy such that the machine cannot serve its legitimate users.
* User to Root Attack (U2R): involves attacks in which the attacker first gains access to a normal user account, and then tries to exploit some vulnerability to gain root access to the system.
* Remote to Local Attack (R2L): involves attacks in which attacker keeps sending packets to a machine over some network. The main purpose in these attacks is to try to find a system vulnerability to gain access as a normal user.
* Probing Attack: these attacks scan the computer networks to find some vulnerability in its security controls.

Table \@ref(tab:nsl-attacks-tab) shows the detailed distribution of the different attacks.

```{r Add kableExtra, echo=FALSE, message=FALSE, warning=FALSE}
options(knitr.table.format = "latex")
library(kableExtra)
```

```{r nsl-attacks-tab, echo=FALSE, message=FALSE, warning=FALSE}
dos_attacks = c("neptune", "back", "land", "pod", "smurf", "teardrop", "mailbomb", "apache2", "processtable", "udpstorm", "worm")
probing_attacks = c("ipsweep", "nmap", "portsweep", "satan", "mscan", "saint")
r2l_attacks = c("ftp_write", "guess_passwd", "imap", "multihop", "phf", "spy", "warezclient", "warezmaster", "sendmail", "named", "snmpgetattack", "snmpguess", "xlock", "xsnoop", "httptunnel")
u2r_attacks = c("buffer_overflow", "loadmodule", "perl", "rootkit", "ps", "sqlattack", "xterm")

attacks_categories <- c(paste(dos_attacks, collapse = ", "), paste(probing_attacks, collapse = ", "), paste(r2l_attacks, collapse = ", "), paste(u2r_attacks, collapse = ", "))
attacks_df <- data.frame(c("DoS", "Probing", "R2L", "U2R"), attacks_categories)
colnames(attacks_df) <- c("Attack Category", "Attacks Included")
kbl(attacks_df, caption = "NSL-KDD Attacks Categories") %>%
  kable_styling(latex_options = c("HOLD_position"), position = "center") %>%
  column_spec(1, border_left = T) %>%
  column_spec(2, width = "30em",border_right = T) %>%
  row_spec(0, bold = T)
```

Figure \@ref(fig:nsl-attacks-fig) shows the distribution of normal and attack connections in NSL-KDD training and testing sets. It is clear that the training set is divided into ~50% normal connections and ~50% for the attacks. Moreover, DoS attack category is dominating the attacks the training set, while R2L and U2R attack categories have few connections. Consequently, it will be challenging to correctly classify R2L and U2R records.

```{r nsl-attacks-fig, echo=FALSE, message=FALSE, warning=FALSE, fig.cap = "Distribution of Normal/Attacks in NSL-KDD Training and Testing Sets", fig.pos = "ht!", out.extra = ""}
training_multi_label <- multi_class_data$train %>%
                          select(label) %>%
                          mutate(set = "Training Set")
testing_multi_label <- multi_class_data$test %>%
                          select(label) %>%
                          mutate(set = "Testing Set")
rbind(training_multi_label, testing_multi_label) %>%
  mutate(multi_label = case_when(label == "X1" ~ "U2R",
                                  label == "X2" ~ "R2L",
                                  label == "X3" ~ "Probing",
                                  label == "X4" ~ "DoS",
                                  label == "X5" ~ "Normal")) %>%
  ggplot(aes(x = fct_infreq(multi_label), group = set)) +
  geom_bar(aes(y = ..prop..), stat = "count") +
  geom_label(aes(label = scales::percent(..prop..), y = ..prop..), stat = "count", vjust = "outward", size = 3.5) +
  geom_label(aes(label = ..count.., y = ..prop..), stat = "count", vjust = "inward", size = 3.5) +
  facet_grid(~factor(set, levels = c("Training Set", "Testing Set"))) +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "Label", y = "Frequency")
```

## Attributes Description
Moreover, NSL-KDD is constructed from 41 attributes or features. These features fall into three main categories as shown in Table \@ref(tab:nsl-attrs-tab):

1. Basic features: these attributes are extracted from a TCP/IP connection.
2. Content features: these attributes are extracted from the data portion of the packet. They are very important to detect R2L and U2R attacks. This is because these attacks usually involve a single connection.
3. Traffic features:
    + Time-based traffic features: these attributes are extracted from connections in the past two seconds that have the same destination or same service as current connection.
    + Connection-based traffic features: these attributes are extracted from last 100 connections that has the same destination or same service as current connection. Extracting such attributes contributes more in detecting probing attacks.

```{r nsl-attrs-tab, echo=FALSE, message=FALSE, warning=FALSE}
features_df_transformer <- function(features_names, category_name) {
  custom_col_summary <- function(col) {
    return(c("Type" = class(col), "Range or Values" = ifelse(is.numeric(col), paste(min(col), max(col), sep = ifelse(length(unique(col)) == 2, ",", "-")), paste(unique(col), collapse = ", "))))
  }
  df <- cbind("Category" = replicate(length(features_names), category_name), tibble::rownames_to_column(data.frame(t(as.data.frame(lapply(X = nsl_kdd_train_csv[, features_names], FUN = custom_col_summary)))), "Feature"))
  df
}
  
basic_df <- features_df_transformer(basic_features, "Basic features")
content_df <- features_df_transformer(content_features, "Content features")
time_based_traffic_df <- features_df_transformer(time_based_traffic_features, "Time-based traffic features")
host_based_traffic_df <- features_df_transformer(host_based_traffic_features, "Connection-based traffic features")
atts_df <- rbind(basic_df, content_df, time_based_traffic_df, host_based_traffic_df)

kbl(atts_df, caption = "NSL-KDD Attributes", col.names = c("Category", "Feature", "Type", "Range/Values"), centering = F) %>%
    kable_styling(position = "left", latex_options = c("HOLD_position")) %>%
    column_spec(1, width = "4.8em", border_left = T) %>%
    column_spec(2, width = "13.5em") %>%
    column_spec(3, width = "3.7em") %>%
    column_spec(4, width = "26.5em", border_right = T) %>%
    row_spec(0, bold = T) %>%
    collapse_rows(1, valign = "middle")
```

# Methodology

## Overview

## Cross Validation

## Remove Zero-Variance Numerical Features

## Normalize Numerical Features using Min-Max

<!-- Another important step before working with feature ranking and classification algorithms is to normalize numeric features. Normalizing a feature means to scale its values to fall into a smaller range [36]. For example, there are features in NSL-KDD dataset that have wide range of values, such as: duration, src_bytes and num_root. While there are other features that have smaller range of values, such as: num_failed_logins, is_host_login, and srv_count. Keeping the features without normalization may cause biasing towards selecting wide range features which may also affect classification performance. To prevent this dominance, we chose to scale all the numeric features to fall in the range of [0, 1] using min-max normalization. Min-max scaling is shown in Eq. (3.2), where x is the value to be scaled in feature X, MinMax(x) is the scaled value of x, Min(X) and Max(X) are the minimum and maximum values respectively in feature X, min and max are the boundaries of the new range. MinMax(x) = min + (max − min)( x −Min(X) Max(X) −Min(X) ) -->

<!-- ## Transform Nominal Features using Probability Density Function (PDF) -->

<!-- Feature ranking and many classification algorithms are mathematical-based. Therefore, it is important to transform the nominal features of a dataset into their numerical representation. NSL-KDD dataset has three nominal features (as stated in Table \@ref(tab:nsl-attrs-tab)): protocol_type, service, and flag. To avoid biasing the data, we did not encode the data with a static value map (e.g. http takes 1, smtp takes 2, and so on). Rather, we applied probability density function as in Eq. (3.1) [29] such that the most frequent nominal value in a column takes the highest numerical value while still being bounded between 0 and 1. This range goes along with the numerical features normalization (as explained in the next section). PDF(x) = occur(x) n (3.1) where occur(x) is the number of occurrences of value x within a column, and n is the total number of records. -->

<!-- ## Classifiers -->

<!-- ## Metrics for Binary Classification -->

<!-- ## Metrics for Multi-class Classification -->

<!-- # Analysis -->

<!-- ## Training Classifiers -->

<!-- ### Training Time for Binary Classifciation -->

<!-- ### Best Fit for Binary Classification -->

<!-- ### Training Time for Multi-class Classification -->

<!-- ### Best Fit for Multi-class Classification -->

<!-- # Results -->

<!-- ## Perform Prediction for Binary Classification -->

<!-- ## Performance for Binary Classification -->

<!-- ## Perform Prediction for Multi-class Classification -->

<!-- ## Performance for Multi-class Classification -->

<!-- # Conclusion -->

\newpage

# References {-}

<div id="refs"></div>
